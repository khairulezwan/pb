{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from pyimagesearch.preprocessing import ImageToArrayPreprocessor\n",
    "from pyimagesearch.preprocessing import AspectAwarePreprocessor\n",
    "from pyimagesearch.datasets import SimpleDatasetLoader\n",
    "from pyimagesearch.nn.conv import FCHeadNet\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'dataset' : '/floyd/input/flowers_17',\n",
    "    'model' : 'flowers17.model',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image data generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] loading images...\n"
     ]
    }
   ],
   "source": [
    "# grab the list of image that we'll be describing, then extract the class label names from the image path\n",
    "print(\"[info] loading images...\")\n",
    "imagePaths = list(paths.list_images(args['dataset']))\n",
    "classNames = [pt.split(os.path.sep)[-2] for pt in imagePaths]\n",
    "classNames = [str(x) for x in np.unique(classNames)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 500/1360\n",
      "[INFO] processed 1000/1360\n"
     ]
    }
   ],
   "source": [
    "# init the image preprocessor\n",
    "aap = AspectAwarePreprocessor(224, 224)\n",
    "iap = ImageToArrayPreprocessor()\n",
    "\n",
    "# load the dataset from disk then scale the raw pixel intensifies to the range\n",
    "# [0, 1]\n",
    "\n",
    "sdl = SimpleDatasetLoader(preprocessors=[aap, iap])\n",
    "(data, labels) = sdl.load(imagePaths, verbose=500)\n",
    "data = data.astype(\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining for testing\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "# convert the label from integer to vector\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load the VGG 16 network, ensuring the head FC layers sets are left off\n",
    "baseModel = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(224,224,3)))\n",
    "\n",
    "# init the new head of the network, a set of FC layers followed by softmax classifier\n",
    "headModel = FCHeadNet.build(baseModel, len(classNames), 256)\n",
    "\n",
    "# place the head FC model on top of the base model -- this will become the actual model we will train\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all layers in the base model and freeze them so they will not be updated during the training process\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "['[INFO] training head....']\n",
      "Epoch 1/25\n",
      "31/31 [==============================] - 105s 3s/step - loss: 7.4981 - accuracy: 0.1690 - val_loss: 1.9522 - val_accuracy: 0.3971\n",
      "Epoch 2/25\n",
      "31/31 [==============================] - 42s 1s/step - loss: 2.1722 - accuracy: 0.3421 - val_loss: 1.6336 - val_accuracy: 0.4618\n",
      "Epoch 3/25\n",
      "31/31 [==============================] - 41s 1s/step - loss: 1.8910 - accuracy: 0.4241 - val_loss: 1.1415 - val_accuracy: 0.6853\n",
      "Epoch 4/25\n",
      "31/31 [==============================] - 42s 1s/step - loss: 1.5327 - accuracy: 0.5282 - val_loss: 1.2398 - val_accuracy: 0.5912\n",
      "Epoch 5/25\n",
      "31/31 [==============================] - 42s 1s/step - loss: 1.4183 - accuracy: 0.5722 - val_loss: 0.7605 - val_accuracy: 0.7765\n",
      "Epoch 6/25\n",
      "31/31 [==============================] - 41s 1s/step - loss: 1.3339 - accuracy: 0.5786 - val_loss: 0.6608 - val_accuracy: 0.7882\n",
      "Epoch 7/25\n",
      "31/31 [==============================] - 42s 1s/step - loss: 1.1101 - accuracy: 0.6535 - val_loss: 0.6307 - val_accuracy: 0.7912\n",
      "Epoch 8/25\n",
      "31/31 [==============================] - 41s 1s/step - loss: 1.0064 - accuracy: 0.6731 - val_loss: 0.6169 - val_accuracy: 0.8088\n",
      "Epoch 9/25\n",
      "31/31 [==============================] - 42s 1s/step - loss: 1.1255 - accuracy: 0.6397 - val_loss: 0.5635 - val_accuracy: 0.8235\n",
      "Epoch 10/25\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.8548 - accuracy: 0.7177 - val_loss: 0.6689 - val_accuracy: 0.7765\n",
      "Epoch 11/25\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.8980 - accuracy: 0.6961 - val_loss: 0.5808 - val_accuracy: 0.8059\n",
      "Epoch 12/25\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.7952 - accuracy: 0.7389 - val_loss: 0.5379 - val_accuracy: 0.8382\n",
      "Epoch 13/25\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.8833 - accuracy: 0.7217 - val_loss: 0.4933 - val_accuracy: 0.8529\n",
      "Epoch 14/25\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.7308 - accuracy: 0.7762 - val_loss: 0.6131 - val_accuracy: 0.8294\n",
      "Epoch 15/25\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.7305 - accuracy: 0.7621 - val_loss: 0.6117 - val_accuracy: 0.8206\n",
      "Epoch 16/25\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.7278 - accuracy: 0.7876 - val_loss: 0.6001 - val_accuracy: 0.8147\n",
      "Epoch 17/25\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.7387 - accuracy: 0.7824 - val_loss: 0.4296 - val_accuracy: 0.8735\n",
      "Epoch 18/25\n",
      "31/31 [==============================] - 43s 1s/step - loss: 0.7040 - accuracy: 0.7763 - val_loss: 0.4335 - val_accuracy: 0.8882\n",
      "Epoch 19/25\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.6842 - accuracy: 0.7843 - val_loss: 0.4178 - val_accuracy: 0.8735\n",
      "Epoch 20/25\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.6564 - accuracy: 0.7846 - val_loss: 0.6111 - val_accuracy: 0.8441\n",
      "Epoch 21/25\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.6316 - accuracy: 0.8014 - val_loss: 0.4389 - val_accuracy: 0.8676\n",
      "Epoch 22/25\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.6170 - accuracy: 0.8130 - val_loss: 0.5858 - val_accuracy: 0.8529\n",
      "Epoch 23/25\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.5285 - accuracy: 0.8198 - val_loss: 0.4351 - val_accuracy: 0.8647\n",
      "Epoch 24/25\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.5539 - accuracy: 0.8196 - val_loss: 0.4505 - val_accuracy: 0.8529\n",
      "Epoch 25/25\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.5795 - accuracy: 0.8168 - val_loss: 0.4461 - val_accuracy: 0.8735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f97f40b7438>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile our model (this needs to be done after our setting our layers to be non-trainable)\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = RMSprop(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# train the head of the network for a few epochs (all other layers are frozen) --\n",
    "# this will allow the new FC layers to start to become init with actual learned values\n",
    "# versus pure random\n",
    "\n",
    "print([\"[INFO] training head....\"])\n",
    "model.fit_generator(aug.flow(trainX, trainY, batch_size=32), validation_data=(testX, testY), epochs=25, steps_per_epoch=len(trainX) // 32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating after init...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    bluebell       0.70      0.80      0.74        20\n",
      "   buttercup       0.65      1.00      0.79        15\n",
      "   coltsfoot       0.83      0.65      0.73        23\n",
      "     cowslip       0.80      0.63      0.71        19\n",
      "      crocus       0.86      0.90      0.88        21\n",
      "    daffodil       0.93      0.81      0.87        16\n",
      "       daisy       1.00      1.00      1.00        16\n",
      "   dandelion       0.86      0.86      0.86        22\n",
      "  fritillary       0.90      0.95      0.92        19\n",
      "        iris       0.96      0.96      0.96        23\n",
      "  lilyvalley       0.93      0.78      0.85        18\n",
      "       pansy       0.93      0.96      0.95        27\n",
      "    snowdrop       1.00      0.85      0.92        20\n",
      "   sunflower       1.00      1.00      1.00        20\n",
      "   tigerlily       0.90      1.00      0.95        18\n",
      "       tulip       0.82      0.70      0.76        20\n",
      "  windflower       0.85      1.00      0.92        23\n",
      "\n",
      "    accuracy                           0.87       340\n",
      "   macro avg       0.88      0.87      0.87       340\n",
      "weighted avg       0.88      0.87      0.87       340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate network after init\n",
    "print(\"[INFO] evaluating after init...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=classNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that the head FC layers have been trained lets unfreeze the final set of conv layers and make them trainable\n",
    "for layer in baseModel.layers[15:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] re-compiling model...\n",
      "[INFO] fine-tuning model...\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.4007 - accuracy: 0.8623 - val_loss: 0.3907 - val_accuracy: 0.8824\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.3334 - accuracy: 0.8887 - val_loss: 0.3303 - val_accuracy: 0.9088\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.2839 - accuracy: 0.9079 - val_loss: 0.3332 - val_accuracy: 0.9059\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.2853 - accuracy: 0.9093 - val_loss: 0.2886 - val_accuracy: 0.9147\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.2523 - accuracy: 0.9126 - val_loss: 0.2868 - val_accuracy: 0.9206\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.2714 - accuracy: 0.9194 - val_loss: 0.2912 - val_accuracy: 0.9206\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.2212 - accuracy: 0.9319 - val_loss: 0.2818 - val_accuracy: 0.9206\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.2583 - accuracy: 0.9244 - val_loss: 0.2786 - val_accuracy: 0.9147\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.2010 - accuracy: 0.9319 - val_loss: 0.3217 - val_accuracy: 0.9000\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.1894 - accuracy: 0.9395 - val_loss: 0.2836 - val_accuracy: 0.9235\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.1854 - accuracy: 0.9380 - val_loss: 0.2951 - val_accuracy: 0.9029\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.2169 - accuracy: 0.9180 - val_loss: 0.2729 - val_accuracy: 0.9206\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.2057 - accuracy: 0.9345 - val_loss: 0.2831 - val_accuracy: 0.9235\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.1865 - accuracy: 0.9342 - val_loss: 0.3092 - val_accuracy: 0.9147\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.1431 - accuracy: 0.9524 - val_loss: 0.3188 - val_accuracy: 0.9265\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.1936 - accuracy: 0.9291 - val_loss: 0.3363 - val_accuracy: 0.9118\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.1751 - accuracy: 0.9472 - val_loss: 0.2882 - val_accuracy: 0.9265\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.1582 - accuracy: 0.9425 - val_loss: 0.2870 - val_accuracy: 0.9265\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.1429 - accuracy: 0.9545 - val_loss: 0.3483 - val_accuracy: 0.9118\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.2063 - accuracy: 0.9372 - val_loss: 0.2818 - val_accuracy: 0.9147\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.1822 - accuracy: 0.9393 - val_loss: 0.2767 - val_accuracy: 0.9265\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.2049 - accuracy: 0.9393 - val_loss: 0.2929 - val_accuracy: 0.9206\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.1761 - accuracy: 0.9461 - val_loss: 0.2801 - val_accuracy: 0.9206\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.1388 - accuracy: 0.9617 - val_loss: 0.3055 - val_accuracy: 0.9176\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.1249 - accuracy: 0.9646 - val_loss: 0.2719 - val_accuracy: 0.9265\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 42s 1s/step - loss: 0.1483 - accuracy: 0.9545 - val_loss: 0.2690 - val_accuracy: 0.9176\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 41s 1s/step - loss: 0.1658 - accuracy: 0.9433 - val_loss: 0.3206 - val_accuracy: 0.9118\n",
      "Epoch 28/100\n",
      " 3/31 [=>............................] - ETA: 32s - loss: 0.1242 - accuracy: 0.9688"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-896cbcf9bbd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m model.fit_generator(aug.flow(trainX, trainY, batch_size=32),\n\u001b[1;32m     12\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m steps_per_epoch=len(trainX) // 32, verbose=1)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    266\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backwards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m           \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m           if isinstance(model.optimizer,\n\u001b[1;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    576\u001b[0m   \u001b[0muse_cudnn_on_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m   \u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m   \u001b[0mshape_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m   \u001b[0;31m# We call the gen_nn_ops backprop functions instead of nn_ops backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape_n\u001b[0;34m(input, out_type, name)\u001b[0m\n\u001b[1;32m    503\u001b[0m   \"\"\"\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mshape_n\u001b[0;34m(input, out_type, name)\u001b[0m\n\u001b[1;32m   9032\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   9033\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ShapeN\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9034\u001b[0;31m         name, _ctx._post_execution_callbacks, input, \"out_type\", out_type)\n\u001b[0m\u001b[1;32m   9035\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9036\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for the changes to the model to take affect we need to recompile\n",
    "# the model, this time using SGD with a *very* small learning rate\n",
    "print(\"[INFO] re-compiling model...\")\n",
    "opt = SGD(lr=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "metrics=[\"accuracy\"])\n",
    "\n",
    "# train the model again, this time fine-tuning *both* the final set\n",
    "# of CONV layers along with our set of FC layers\n",
    "print(\"[INFO] fine-tuning model...\")\n",
    "model.fit_generator(aug.flow(trainX, trainY, batch_size=32),\n",
    "validation_data=(testX, testY), epochs=100,\n",
    "steps_per_epoch=len(trainX) // 32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating after fine-tuning...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    bluebell       1.00      0.90      0.95        20\n",
      "   buttercup       0.93      0.93      0.93        15\n",
      "   coltsfoot       0.85      0.74      0.79        23\n",
      "     cowslip       1.00      0.74      0.85        19\n",
      "      crocus       0.81      1.00      0.89        21\n",
      "    daffodil       0.93      0.81      0.87        16\n",
      "       daisy       1.00      1.00      1.00        16\n",
      "   dandelion       0.90      0.86      0.88        22\n",
      "  fritillary       1.00      1.00      1.00        19\n",
      "        iris       0.96      0.96      0.96        23\n",
      "  lilyvalley       0.94      0.89      0.91        18\n",
      "       pansy       0.90      1.00      0.95        27\n",
      "    snowdrop       1.00      0.95      0.97        20\n",
      "   sunflower       1.00      1.00      1.00        20\n",
      "   tigerlily       0.86      1.00      0.92        18\n",
      "       tulip       0.69      0.90      0.78        20\n",
      "  windflower       1.00      0.91      0.95        23\n",
      "\n",
      "    accuracy                           0.92       340\n",
      "   macro avg       0.93      0.92      0.92       340\n",
      "weighted avg       0.93      0.92      0.92       340\n",
      "\n",
      "[INFO] serializing model...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: flowers17.model/assets\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network on the fine-tuned model\n",
    "print(\"[INFO] evaluating after fine-tuning...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "predictions.argmax(axis=1), target_names=classNames))\n",
    "\n",
    "\n",
    "# save the model to disk\n",
    "print(\"[INFO] serializing model...\")\n",
    "model.save(args[\"model\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
