{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyimagesearch.preprocessing import ImageToArrayPreprocessor\n",
    "from pyimagesearch.preprocessing import AspectAwarePreprocessor\n",
    "from pyimagesearch.datasets import SimpleDatasetLoader\n",
    "from pyimagesearch.nn.conv import FCHeadNet\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from imutils import paths\n",
    "import numpy as np \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'dataset' : '',\n",
    "    'model' : '',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image data generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the list of image that we'll be describing, then extract the class label names from the image path\n",
    "print(\"[info] loading images...\")\n",
    "imagePaths = list(paths.list_images(args['dataset']))\n",
    "classNames = [pt.split(os.path.sep)[-2] for pt in imagePaths]\n",
    "classNames = [str(x) for x in np.unique(classNames)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the image preprocessor\n",
    "aap = AspectAwarePreprocessor(224, 224)\n",
    "iap = ImageToArrayPreprocessor()\n",
    "\n",
    "# load the dataset from disk then scale the raw pixel intensifies to the range\n",
    "# [0, 1]\n",
    "\n",
    "sdl = SimpleDatasetLoader(preprocessors=(aap, iap))\n",
    "(data, labels) = sdl.load(imagePaths, verbose=500)\n",
    "data = data.astype(\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining for testing\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# convert the label from integer to vector\n",
    "trainY = LabelBinarizer().fit_transform(trainY)\n",
    "testY = LabelBinarizer().fit(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the VGG 16 network, ensuring the head FC layers sets are left off\n",
    "baseModel = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(224,224,3)))\n",
    "\n",
    "# init the new head of the network, a set of FC layers followed by softmax classifier\n",
    "headModel = FCHeadNet.build(baseModel, len(classNames), 256)\n",
    "\n",
    "# place the head FC model on top of the base model -- this will become the actual model we will train\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all layers in the base model and freeze them so they will not be updated during the training process\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile our model (this needs to be done after our setting our layers to be non-trainable)\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = RMSprop(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# train the head of the network for a few epochs (all other layers are frozen) --\n",
    "# this will allow the new FC layers to start to become init with actual learned values\n",
    "# versus pure random\n",
    "\n",
    "print([\"[INFO] training head....\"])\n",
    "model.fit_generator(aug.flow(trainX, trainY, batch_size=32), validation_data=(testX, testY), epochs=25, steps_per_epoch=len(trainX) // 32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate network after init\n",
    "print(\"[INFO] evaluating after init...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=classNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that the head FC layers have been trained lets unfreeze the final set of conv layers and make them trainable\n",
    "for layer in baseModel.layers[15:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the changes to the model to take affect we need to recompile\n",
    "# the model, this time using SGD with a *very* small learning rate\n",
    "print(\"[INFO] re-compiling model...\")\n",
    "opt = SGD(lr=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "metrics=[\"accuracy\"])\n",
    "\n",
    "# train the model again, this time fine-tuning *both* the final set\n",
    "# of CONV layers along with our set of FC layers\n",
    "print(\"[INFO] fine-tuning model...\")\n",
    "model.fit_generator(aug.flow(trainX, trainY, batch_size=32),\n",
    "validation_data=(testX, testY), epochs=100,\n",
    "steps_per_epoch=len(trainX) // 32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the network on the fine-tuned model\n",
    "print(\"[INFO] evaluating after fine-tuning...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "predictions.argmax(axis=1), target_names=classNames))\n",
    "\n",
    "\n",
    "# save the model to disk\n",
    "print(\"[INFO] serializing model...\")\n",
    "model.save(args[\"model\"])"
   ]
  }
 ]
}